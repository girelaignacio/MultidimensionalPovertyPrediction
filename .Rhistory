source("C:/Users/girel/Dropbox/PLS-WBIndicatos/main_function_beta.R", echo=TRUE)
pls_lm <- list(label = "PLS-lm",
library = c("chemometrics", "stats"),
type = "Regression",
## Tune over both parameters at the same time
parameters = data.frame(parameter = c('ncomp'),
class = c("numeric"),
label = c('#Components')),
grid = function(x, y, len = NULL, search = "grid") {
if(search == "grid") {
grid <- expand.grid(ncomp = seq(1, min(ncol(x) - 1, len), by = 1))
} else {
grid <- expand.grid(ncomp = sample(1:ncol(x), size = len))
}
grid
},
loop = NULL,
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
## First fit the pls model, generate the training set scores,
## then attach what is needed to the model object to
## be used later
# x : metric data
# x_nm : non-metric data
PLS <- pls.datafilter(y, x, dimensions = param$ncomp, scale = FALSE)
X <- PLS$X
X_nm <- PLS$X_nm
loadings <- PLS$W
scores <- as.matrix(X) %*% loadings
colnames(scores) <- paste("score", 1:param$ncomp, sep = "")
data <- scores
data <- as.data.frame(cbind(scores,X_nm))
colnames.pred <- colnames(data)
data$y <- y
model.formula <- as.formula(paste0("y ~ ", paste0(colnames.pred,collapse = " + "),sep = ""))
model <- lm(model.formula, data = data, na.action = "na.exclude")
model$projection <- loadings
model
},
predict = function(modelFit, newdata, submodels = NULL) {
## Now apply the same scaling to the new samples
col.region_ <- grep("^region_", colnames(newdata))
col.time_ <- grep("^time_", colnames(newdata))
col.out <- c(col.region_, col.time_)
X <- newdata[, - col.out]
print(dim(X))
print(dim(newdata))
scores <- as.matrix(X) %*% modelFit$projection
colnames(scores) <- paste("score", 1:ncol(scores), sep = "")
scores <- as.data.frame(scores)
#X_nm <- newdata[, grep("^region_",colnames(newdata))]
X_nm <- newdata[, col.out]
newdata <- cbind(X_nm,scores)
## Predict the linear model
predict(modelFit, newdata)
},
prob = NULL,
varImp = NULL,
predictors = function(x, ...) rownames(x$projection),
levels = function(x) x$obsLevels,
sort = function(x) x[order(x[,1]),])
library(devtools)
load_all()
check()
load_all()
check()
devtools::load_all()
target <- "MPI"
data <- preprocessing.data(which.data = 1, target = "MPI", time.format = "trend")
### Set parameters for tuning parameters
n_folds <- 5
n_comp <- 10
train_index <- caret::createDataPartition(data[,target], p = 0.8, list = FALSE, times = 1)
data_train <- data[train_index,]
data_test <- data[-train_index,]
ytrain <- data_train[,target] ; Xtrain <- data_train[,-1]
ytest <- data_test[,target] ; Xtest <- data_test[,-1]
### Set train fitting control
CV_index <- caret::createResample(data_train[,target])
fitControl <- caret::trainControl(method="cv",
number=n_folds,
index = CV_index)
pls_lm.fit <- caret::train(x = Xtrain, y = ytrain,
method = pls_lm(),
ncomp = 10,
trControl = fitControl,
verbose = FALSE)
ypred <- predict(pls_lm.fit, Xtest)
mean((ytest - ypred)^2)
PLS-lm <- list(label = "PLS-lm",
library = c("chemometrics", "stats"),
type = "Regression",
## Tune over both parameters at the same time
parameters = data.frame(parameter = c('ncomp'),
class = c("numeric"),
label = c('#Components')),
grid = function(x, y, len = NULL, search = "grid") {
if(search == "grid") {
grid <- expand.grid(ncomp = seq(1, min(ncol(x) - 1, len), by = 1))
} else {
grid <- expand.grid(ncomp = sample(1:ncol(x), size = len))
}
grid
},
loop = NULL,
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
## First fit the pls model, generate the training set scores,
## then attach what is needed to the model object to
## be used later
# x : metric data
# x_nm : non-metric data
PLS <- pls.datafilter(y, x, dimensions = param$ncomp, scale = FALSE)
X <- PLS$X
X_nm <- PLS$X_nm
loadings <- PLS$W
scores <- as.matrix(X) %*% loadings
colnames(scores) <- paste("score", 1:param$ncomp, sep = "")
data <- scores
data <- as.data.frame(cbind(scores,X_nm))
colnames.pred <- colnames(data)
data$y <- y
model.formula <- stats::as.formula(paste0("y ~ ", paste0(colnames.pred,collapse = " + "),sep = ""))
model <- stats::lm(model.formula, data = data, na.action = "na.exclude")
model$projection <- loadings
model
},
predict = function(modelFit, newdata, submodels = NULL) {
## Now apply the same scaling to the new samples
col.region_ <- grep("^region_", colnames(newdata))
col.time_ <- grep("^time_", colnames(newdata))
col.out <- c(col.region_, col.time_)
X <- newdata[, - col.out]
print(dim(X))
print(dim(newdata))
scores <- as.matrix(X) %*% modelFit$projection
colnames(scores) <- paste("score", 1:ncol(scores), sep = "")
scores <- as.data.frame(scores)
#X_nm <- newdata[, grep("^region_",colnames(newdata))]
X_nm <- newdata[, col.out]
newdata <- cbind(X_nm,scores)
## Predict the linear model
stats::predict(modelFit, newdata)
},
prob = NULL,
varImp = NULL,
predictors = function(x, ...) rownames(x$projection),
levels = function(x) x$obsLevels,
sort = function(x) x[order(x[,1]),])
PLS-lm <- list(label = "PLS-lm",
library = c("chemometrics", "stats"),
type = "Regression",
## Tune over both parameters at the same time
parameters = data.frame(parameter = c('ncomp'),
class = c("numeric"),
label = c('#Components')),
grid = function(x, y, len = NULL, search = "grid") {
if(search == "grid") {
grid <- expand.grid(ncomp = seq(1, min(ncol(x) - 1, len), by = 1))
} else {
grid <- expand.grid(ncomp = sample(1:ncol(x), size = len))
}
grid
},
loop = NULL,
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
## First fit the pls model, generate the training set scores,
## then attach what is needed to the model object to
## be used later
# x : metric data
# x_nm : non-metric data
PLS <- pls.datafilter(y, x, dimensions = param$ncomp, scale = FALSE)
X <- PLS$X
X_nm <- PLS$X_nm
loadings <- PLS$W
scores <- as.matrix(X) %*% loadings
colnames(scores) <- paste("score", 1:param$ncomp, sep = "")
data <- scores
data <- as.data.frame(cbind(scores,X_nm))
colnames.pred <- colnames(data)
data$y <- y
model.formula <- stats::as.formula(paste0("y ~ ", paste0(colnames.pred,collapse = " + "),sep = ""))
model <- stats::lm(model.formula, data = data, na.action = "na.exclude")
model$projection <- loadings
model
},
predict = function(modelFit, newdata, submodels = NULL) {
## Now apply the same scaling to the new samples
col.region_ <- grep("^region_", colnames(newdata))
col.time_ <- grep("^time_", colnames(newdata))
col.out <- c(col.region_, col.time_)
X <- newdata[, - col.out]
print(dim(X))
print(dim(newdata))
scores <- as.matrix(X) %*% modelFit$projection
colnames(scores) <- paste("score", 1:ncol(scores), sep = "")
scores <- as.data.frame(scores)
#X_nm <- newdata[, grep("^region_",colnames(newdata))]
X_nm <- newdata[, col.out]
newdata <- cbind(X_nm,scores)
## Predict the linear model
stats::predict(modelFit, newdata)
},
prob = NULL,
varImp = NULL,
predictors = function(x, ...) rownames(x$projection),
levels = function(x) x$obsLevels,
sort = function(x) x[order(x[,1]),])
PLS-lm <- list(label = "PLS-lm",
library = c("chemometrics", "stats"),
type = "Regression",
## Tune over both parameters at the same time
parameters = data.frame(parameter = c('ncomp'),
class = c("numeric"),
label = c('#Components')),
grid = function(x, y, len = NULL, search = "grid") {
if(search == "grid") {
grid <- expand.grid(ncomp = seq(1, min(ncol(x) - 1, len), by = 1))
} else {
grid <- expand.grid(ncomp = sample(1:ncol(x), size = len))
}
grid
},
loop = NULL,
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
pls.datafilter <- function(y, x, dimensions, scale = FALSE){
col.region_ <- grep("^region_", colnames(x))
col.time_ <- grep("^time_", colnames(x))
col.out <- c(col.region_,col.time_)
X <- x[,- col.out]
X_nm <- x[, col.out]
W <- chemometrics::pls1_nipals(X, y, a = dimensions, scale = scale)$W
out <- list(W=W, X = X, X_nm = X_nm)
}
## First fit the pls model, generate the training set scores,
## then attach what is needed to the model object to
## be used later
# x : metric data
# x_nm : non-metric data
PLS <- pls.datafilter(y, x, dimensions = param$ncomp, scale = FALSE)
X <- PLS$X
X_nm <- PLS$X_nm
loadings <- PLS$W
scores <- as.matrix(X) %*% loadings
colnames(scores) <- paste("score", 1:param$ncomp, sep = "")
data <- scores
data <- as.data.frame(cbind(scores,X_nm))
colnames.pred <- colnames(data)
data$y <- y
model.formula <- stats::as.formula(paste0("y ~ ", paste0(colnames.pred,collapse = " + "),sep = ""))
model <- stats::lm(model.formula, data = data, na.action = "na.exclude")
model$projection <- loadings
model
},
predict = function(modelFit, newdata, submodels = NULL) {
## Now apply the same scaling to the new samples
col.region_ <- grep("^region_", colnames(newdata))
col.time_ <- grep("^time_", colnames(newdata))
col.out <- c(col.region_, col.time_)
X <- newdata[, - col.out]
print(dim(X))
print(dim(newdata))
scores <- as.matrix(X) %*% modelFit$projection
colnames(scores) <- paste("score", 1:ncol(scores), sep = "")
scores <- as.data.frame(scores)
#X_nm <- newdata[, grep("^region_",colnames(newdata))]
X_nm <- newdata[, col.out]
newdata <- cbind(X_nm,scores)
## Predict the linear model
stats::predict(modelFit, newdata)
},
prob = NULL,
varImp = NULL,
predictors = function(x, ...) rownames(x$projection),
levels = function(x) x$obsLevels,
sort = function(x) x[order(x[,1]),])
PLS-lm <- list(label = "PLS-lm",
library = c("chemometrics", "stats"),
type = "Regression",
## Tune over both parameters at the same time
parameters = data.frame(parameter = c('ncomp'),
class = c("numeric"),
label = c('#Components')),
grid = function(x, y, len = NULL, search = "grid") {
if(search == "grid") {
grid <- expand.grid(ncomp = seq(1, min(ncol(x) - 1, len), by = 1))
} else {
grid <- expand.grid(ncomp = sample(1:ncol(x), size = len))
}
grid
},
loop = NULL,
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
pls.datafilter <- function(y, x, dimensions, scale = FALSE){
col.region_ <- grep("^region_", colnames(x))
col.time_ <- grep("^time_", colnames(x))
col.out <- c(col.region_,col.time_)
X <- x[,- col.out]
X_nm <- x[, col.out]
W <- chemometrics::pls1_nipals(X, y, a = dimensions, scale = scale)$W
out <- list(W=W, X = X, X_nm = X_nm)
}
## First fit the pls model, generate the training set scores,
## then attach what is needed to the model object to
## be used later
# x : metric data
# x_nm : non-metric data
PLS <- pls.datafilter(y, x, dimensions = param$ncomp, scale = FALSE)
X <- PLS$X
X_nm <- PLS$X_nm
loadings <- PLS$W
scores <- as.matrix(X) %*% loadings
colnames(scores) <- paste("score", 1:param$ncomp, sep = "")
data <- scores
data <- as.data.frame(cbind(scores,X_nm))
colnames.pred <- colnames(data)
data$y <- y
model.formula <- stats::as.formula(paste0("y ~ ", paste0(colnames.pred,collapse = " + "),sep = ""))
model <- stats::lm(model.formula, data = data, na.action = "na.exclude")
model$projection <- loadings
model
},
predict = function(modelFit, newdata, submodels = NULL) {
## Now apply the same scaling to the new samples
col.region_ <- grep("^region_", colnames(newdata))
col.time_ <- grep("^time_", colnames(newdata))
col.out <- c(col.region_, col.time_)
X <- newdata[, - col.out]
print(dim(X))
print(dim(newdata))
scores <- as.matrix(X) %*% modelFit$projection
colnames(scores) <- paste("score", 1:ncol(scores), sep = "")
scores <- as.data.frame(scores)
#X_nm <- newdata[, grep("^region_",colnames(newdata))]
X_nm <- newdata[, col.out]
newdata <- cbind(X_nm,scores)
## Predict the linear model
stats::predict(modelFit, newdata)
},
prob = NULL,
varImp = NULL,
predictors = function(x, ...) rownames(x$projection),
levels = function(x) x$obsLevels,
sort = function(x) x[order(x[,1]),])
pls.lm <- list(label = "PLS-lm",
library = c("chemometrics", "stats"),
type = "Regression",
## Tune over both parameters at the same time
parameters = data.frame(parameter = c('ncomp'),
class = c("numeric"),
label = c('#Components')),
grid = function(x, y, len = NULL, search = "grid") {
if(search == "grid") {
grid <- expand.grid(ncomp = seq(1, min(ncol(x) - 1, len), by = 1))
} else {
grid <- expand.grid(ncomp = sample(1:ncol(x), size = len))
}
grid
},
loop = NULL,
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
## First fit the pls model, generate the training set scores,
## then attach what is needed to the model object to
## be used later
# x : metric data
# x_nm : non-metric data
PLS <- pls.datafilter(y, x, dimensions = param$ncomp, scale = FALSE)
X <- PLS$X
X_nm <- PLS$X_nm
loadings <- PLS$W
scores <- as.matrix(X) %*% loadings
colnames(scores) <- paste("score", 1:param$ncomp, sep = "")
data <- scores
data <- as.data.frame(cbind(scores,X_nm))
colnames.pred <- colnames(data)
data$y <- y
model.formula <- stats::as.formula(paste0("y ~ ", paste0(colnames.pred,collapse = " + "),sep = ""))
model <- stats::lm(model.formula, data = data, na.action = "na.exclude")
model$projection <- loadings
model
},
predict = function(modelFit, newdata, submodels = NULL) {
## Now apply the same scaling to the new samples
col.region_ <- grep("^region_", colnames(newdata))
col.time_ <- grep("^time_", colnames(newdata))
col.out <- c(col.region_, col.time_)
X <- newdata[, - col.out]
print(dim(X))
print(dim(newdata))
scores <- as.matrix(X) %*% modelFit$projection
colnames(scores) <- paste("score", 1:ncol(scores), sep = "")
scores <- as.data.frame(scores)
#X_nm <- newdata[, grep("^region_",colnames(newdata))]
X_nm <- newdata[, col.out]
newdata <- cbind(X_nm,scores)
## Predict the linear model
stats::predict(modelFit, newdata)
},
prob = NULL,
varImp = NULL,
predictors = function(x, ...) rownames(x$projection),
levels = function(x) x$obsLevels,
sort = function(x) x[order(x[,1]),])
usethis::use_data(pls.lm,internal = T)
usethis::use_data(pls.lm,internal = T)
usethis::use_data(pls.lm,internal = T)
load("C:/Users/girel/MultidimensionalPovertyPrediction/R/sysdata.rda")
system.file("R", "sysdata.rda", package = "MultidimensionalPovertyPredictin")
system.file("R", "sysdata.rda", package = "MultidimensionalPovertyPrediction")
devtools::load_all()
target <- "MPI"
data <- preprocessing.data(which.data = 1, target = "MPI", time.format = "trend")
### Set parameters for tuning parameters
n_folds <- 5
n_comp <- 10
train_index <- caret::createDataPartition(data[,target], p = 0.8, list = FALSE, times = 1)
data_train <- data[train_index,]
data_test <- data[-train_index,]
ytrain <- data_train[,target] ; Xtrain <- data_train[,-1]
ytest <- data_test[,target] ; Xtest <- data_test[,-1]
### Set train fitting control
CV_index <- caret::createResample(data_train[,target])
fitControl <- caret::trainControl(method="cv",
number=n_folds,
index = CV_index)
pls.lm
pls_lm.fit <- caret::train(x = Xtrain, y = ytrain,
method = pls.lm,
ncomp = 10,
trControl = fitControl,
verbose = FALSE)
ypred <- predict(pls_lm.fit, Xtest)
mean((ytest - ypred)^2)
check()
pls.lm <- list(label = "PLS-lm",
library = c("chemometrics", "stats"),
type = "Regression",
## Tune over both parameters at the same time
parameters = data.frame(parameter = c('ncomp'),
class = c("numeric"),
label = c('#Components')),
grid = function(x, y, len = NULL, search = "grid") {
if(search == "grid") {
grid <- expand.grid(ncomp = seq(1, min(ncol(x) - 1, len), by = 1))
} else {
grid <- expand.grid(ncomp = sample(1:ncol(x), size = len))
}
grid
},
loop = NULL,
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
## First fit the pls model, generate the training set scores,
## then attach what is needed to the model object to
## be used later
# x : metric data
# x_nm : non-metric data
PLS <- pls.datafilter(y, x, dimensions = param$ncomp, scale = FALSE)
X <- PLS$X
X_nm <- PLS$X_nm
loadings <- PLS$W
scores <- as.matrix(X) %*% loadings
colnames(scores) <- paste("score", 1:param$ncomp, sep = "")
data <- scores
data <- as.data.frame(cbind(scores,X_nm))
colnames.pred <- colnames(data)
data$y <- y
model.formula <- stats::as.formula(paste0("y ~ ", paste0(colnames.pred,collapse = " + "),sep = ""))
model <- stats::lm(model.formula, data = data, na.action = "na.exclude")
model$projection <- loadings
model
},
predict = function(modelFit, newdata, submodels = NULL) {
## Now apply the same scaling to the new samples
col.region_ <- grep("^region_", colnames(newdata))
col.time_ <- grep("^time_", colnames(newdata))
col.out <- c(col.region_, col.time_)
X <- newdata[, - col.out]
scores <- as.matrix(X) %*% modelFit$projection
colnames(scores) <- paste("score", 1:ncol(scores), sep = "")
scores <- as.data.frame(scores)
#X_nm <- newdata[, grep("^region_",colnames(newdata))]
X_nm <- newdata[, col.out]
newdata <- cbind(X_nm,scores)
## Predict the linear model
stats::predict(modelFit, newdata)
},
prob = NULL,
varImp = NULL,
predictors = function(x, ...) rownames(x$projection),
levels = function(x) x$obsLevels,
sort = function(x) x[order(x[,1]),])
usethis::use_data(pls.lm,internal = T)
ff <- gl(3,1, labels=LETTERS[3:1])
ff[1] # C
switch(ff[1], A = "I am A", B="Bb..", C=" is C")
call.model <- function(model){
model <- switch(model,
pls.lm = "call pls lm function")
}
call.model("pls.fit")
call.model("pls.lm")
A <- call.model("pls.lm")
A
call.model <- function(model){
model <- switch(model,
pls.lm = "call pls lm model",
pls.lasso = "call pls lasso model")
}
call.model("pls.lm")
A <- call.model("pls.lm")
A
A <- call.model("pls.lasso")
A <- call.model("pls.lasso")
A
