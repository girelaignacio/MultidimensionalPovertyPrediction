webscreapped_data <- read.table("~/pls-naroni/bigdata.txt")
webscrapped_data <- read.table("~/pls-naroni/bigdata.txt")
View(webscrapped_data)
webscrapped_data <- webscrapped_data[,-c("variable")]
webscrapped_data <- webscrapped_data[,-7]
webscrapped_data0 <- webscrapped_data
usethis::use_data(webscrapped_data0)
load_all()
devtools:::load_all()
file <- webscrapped_data0
View(file)
df = read.delim(file, header = TRUE, sep = " ", dec = ".")
View(file)
str(webscrapped_data0)
dataframes <- c("webscrapped_data0.rda")
which.df <- match(1, dataframes)
which.df <- match(1, dataframes, F)
match.call(expand.dots = TRUE)
names(match.call(expand.dots = TRUE))
match.arg(target)
devtools::load_all()
target <- "MPI"
df <- MultidimensionalPovertyPrediction::data1
data <- preprocessing.dataframe(which.data = 1, target = "MPI", time.format = "trend")
### Set parameters for tuning parameters
n_folds <- 5
n_comp <- 10
train_index <- caret::createDataPartition(selected.df[,target], p = 0.8, list = FALSE, times = 1)
data_train <- selected.df[train_index,]
data_test <- selected.df[-train_index,]
train_index <- caret::createDataPartition(data[,target], p = 0.8, list = FALSE, times = 1)
data_train <- selected.df[train_index,]
data_test <- selected.df[-train_index,]
ytrain <- data_train[,target] ; Xtrain <- data_train[,-1]
data_train <- data[train_index,]
data_test <- data[-train_index,]
ytrain <- data_train[,target] ; Xtrain <- data_train[,-1]
ytest <- data_test[,target] ; Xtest <- data_test[,-1]
### Set train fitting control
fitControl <- caret::trainControl(method="cv",
number=n_folds,
index = caret::createResample(data_train[,target]))
pls_lm.fit <- caret::train(x = Xtrain, y = ytrain,
method = pls_lm,
ncomp = 10,
trControl = fitControl,
verbose = FALSE)
devtools::load_all()
target <- "MPI"
df <- MultidimensionalPovertyPrediction::data1
data <- preprocessing.dataframe(which.data = 1, target = "MPI", time.format = "trend")
### Set parameters for tuning parameters
n_folds <- 5
n_comp <- 10
train_index <- caret::createDataPartition(data[,target], p = 0.8, list = FALSE, times = 1)
data_train <- data[train_index,]
data_test <- data[-train_index,]
ytrain <- data_train[,target] ; Xtrain <- data_train[,-1]
ytest <- data_test[,target] ; Xtest <- data_test[,-1]
### Set train fitting control
fitControl <- caret::trainControl(method="cv",
number=n_folds,
index = caret::createResample(data_train[,target]))
pls_lm.fit <- caret::train(x = Xtrain, y = ytrain,
method = pls_lm,
ncomp = 10,
trControl = fitControl,
verbose = FALSE)
source("~/.active-rstudio-document", echo=TRUE)
ypred <- predict(lm.fit, Xtest)
ypred <- predict(pls_lm.fit, Xtest)
mean((ytest - ypred)^2)
devtools::load_all()
devtools::check()
devtools::check()
usethis::use_package(c("stats","df","model.matrix"))
usethis::use_package("model.matrix")
usethis::use_package("model.matrix", min_version = T)
usethis::use_package("stats", min_version = T)
usethis::use_package("model.frame", min_version = T)
check()
devtools::check()
devtools::check()
usethis::use_package("chemometrics")
devtools::check()
devtools::load_all()
target <- "MPI"
df <- MultidimensionalPovertyPrediction::data1
data <- preprocessing.dataframe(which.data = 1, target = "MPI", time.format = "trend")
### Set parameters for tuning parameters
n_folds <- 5
n_comp <- 10
train_index <- caret::createDataPartition(data[,target], p = 0.8, list = FALSE, times = 1)
data_train <- data[train_index,]
data_test <- data[-train_index,]
ytrain <- data_train[,target] ; Xtrain <- data_train[,-1]
ytest <- data_test[,target] ; Xtest <- data_test[,-1]
### Set train fitting control
fitControl <- caret::trainControl(method="cv",
number=n_folds,
index = caret::createResample(data_train[,target]))
pls_lm.fit <- caret::train(x = Xtrain, y = ytrain,
method = pls_lm,
ncomp = 10,
trControl = fitControl,
verbose = FALSE)
ypred <- predict(pls_lm.fit, Xtest)
mean((ytest - ypred)^2)
devtools
devtools::check()
devtools::install_github("girelaignacio/MultidimensionalPovertyPrediction")
devtools::load_all()
target <- "MPI"
df <- MultidimensionalPovertyPrediction::data1
data <- preprocessing.data(which.data = 1, target = "MPI", time.format = "trend")
elnet=c(x,is.sparse,y,weights,offset,type.gaussian,alpha,nobs,nvars,jd,vp,cl,ne,nx,nlam,flmin,ulam,thresh,isd,intr,vnames,maxit,pb)
lognet=c(x,is.sparse,ix,jx,y,weights,offset,alpha,nobs,nvars,jd,vp,cl,ne,nx,nlam,flmin,ulam,thresh,isd,intr,vnames,maxit,kopt,family,pb)
##########################################
# tiempo discreto
Xtrain_td = subset(Xtrain, select=-c(year_trend))
Xtest_td = subset(Xtest, select=-c(year_trend))
source("dataframes.R")
source("splits.R")
source("kfold_cv_selection.R")
source("pls.R")
#########################################################
#dataframes (correr la primera vez sin comentar)
datas = list()
for (i in c(2)){
nombre <- paste("plsdata", i, sep="_")
datas[[nombre]] = selectdfs(plsdata,i)
}
#########################################################
df = datas[[1]]; target = "mpi_Other"
nfolds <- 5
df$year_trend <- as.numeric(as.character(df$year_Other))
datas = list()
for (i in c(2)){
nombre <- paste("plsdata", i, sep="_")
datas[[nombre]] = selectdfs(plsdata,i)
}
source("dataframes.R")
devtools::check()
pls_lm <- list(label = "PLS-lm",
library = c("chemometrics", "stats"),
type = "Regression",
## Tune over both parameters at the same time
parameters = data.frame(parameter = c('ncomp'),
class = c("numeric"),
label = c('#Components')),
grid = function(x, y, len = NULL, search = "grid") {
if(search == "grid") {
grid <- expand.grid(ncomp = seq(1, min(ncol(x) - 1, len), by = 1))
} else {
grid <- expand.grid(ncomp = sample(1:ncol(x), size = len))
}
grid
},
loop = NULL,
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
## First fit the pls model, generate the training set scores,
## then attach what is needed to the model object to
## be used later
# x : metric data
# x_nm : non-metric data
PLS <- pls.datafilter(y, x, dimensions = param$ncomp, scale = FALSE)
X <- PLS$X
X_nm <- PLS$X_nm
loadings <- PLS$W
scores <- as.matrix(X) %*% loadings
colnames(scores) <- paste("score", 1:param$ncomp, sep = "")
data <- scores
data <- as.data.frame(cbind(scores,X_nm))
colnames.pred <- colnames(data)
data$y <- y
model.formula <- as.formula(paste0("y ~ ", paste0(colnames.pred,collapse = " + "),sep = ""))
model <- lm(model.formula, data = data, na.action = "na.exclude")
model$projection <- loadings
model
},
predict = function(modelFit, newdata, submodels = NULL) {
## Now apply the same scaling to the new samples
col.region_ <- grep("^region_", colnames(newdata))
col.time_ <- grep("^time_", colnames(newdata))
col.out <- c(col.region_, col.time_)
X <- newdata[, - col.out]
print(dim(X))
print(dim(newdata))
scores <- as.matrix(X) %*% modelFit$projection
colnames(scores) <- paste("score", 1:ncol(scores), sep = "")
scores <- as.data.frame(scores)
#X_nm <- newdata[, grep("^region_",colnames(newdata))]
X_nm <- newdata[, col.out]
newdata <- cbind(X_nm,scores)
## Predict the linear model
predict(modelFit, newdata)
},
prob = NULL,
varImp = NULL,
predictors = function(x, ...) rownames(x$projection),
levels = function(x) x$obsLevels,
sort = function(x) x[order(x[,1]),])
usethis::use_data_raw(name="pls_lm")
devtools::load_all()
devtools::load_all()
target <- "MPI"
data <- preprocessing.data(which.data = 1, target = "MPI", time.format = "trend")
### Set parameters for tuning parameters
n_folds <- 5
n_comp <- 10
train_index <- caret::createDataPartition(data[,target], p = 0.8, list = FALSE, times = 1)
data_train <- data[train_index,]
data_test <- data[-train_index,]
ytrain <- data_train[,target] ; Xtrain <- data_train[,-1]
ytest <- data_test[,target] ; Xtest <- data_test[,-1]
### Set train fitting control
CV_index <- caret::createResample(data_train[,target])
fitControl <- caret::trainControl(method="cv",
number=n_folds,
index = CV_index)
pls_lm.fit <- caret::train(x = Xtrain, y = ytrain,
method = pls_lm(),
ncomp = 10,
trControl = fitControl,
verbose = FALSE)
View(pls_lm.fit)
source("C:/Users/girel/Dropbox/PLS-WBIndicatos/main_function_beta.R", echo=TRUE)
pls_lm <- list(label = "PLS-lm",
library = c("chemometrics", "stats"),
type = "Regression",
## Tune over both parameters at the same time
parameters = data.frame(parameter = c('ncomp'),
class = c("numeric"),
label = c('#Components')),
grid = function(x, y, len = NULL, search = "grid") {
if(search == "grid") {
grid <- expand.grid(ncomp = seq(1, min(ncol(x) - 1, len), by = 1))
} else {
grid <- expand.grid(ncomp = sample(1:ncol(x), size = len))
}
grid
},
loop = NULL,
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
## First fit the pls model, generate the training set scores,
## then attach what is needed to the model object to
## be used later
# x : metric data
# x_nm : non-metric data
PLS <- pls.datafilter(y, x, dimensions = param$ncomp, scale = FALSE)
X <- PLS$X
X_nm <- PLS$X_nm
loadings <- PLS$W
scores <- as.matrix(X) %*% loadings
colnames(scores) <- paste("score", 1:param$ncomp, sep = "")
data <- scores
data <- as.data.frame(cbind(scores,X_nm))
colnames.pred <- colnames(data)
data$y <- y
model.formula <- as.formula(paste0("y ~ ", paste0(colnames.pred,collapse = " + "),sep = ""))
model <- lm(model.formula, data = data, na.action = "na.exclude")
model$projection <- loadings
model
},
predict = function(modelFit, newdata, submodels = NULL) {
## Now apply the same scaling to the new samples
col.region_ <- grep("^region_", colnames(newdata))
col.time_ <- grep("^time_", colnames(newdata))
col.out <- c(col.region_, col.time_)
X <- newdata[, - col.out]
print(dim(X))
print(dim(newdata))
scores <- as.matrix(X) %*% modelFit$projection
colnames(scores) <- paste("score", 1:ncol(scores), sep = "")
scores <- as.data.frame(scores)
#X_nm <- newdata[, grep("^region_",colnames(newdata))]
X_nm <- newdata[, col.out]
newdata <- cbind(X_nm,scores)
## Predict the linear model
predict(modelFit, newdata)
},
prob = NULL,
varImp = NULL,
predictors = function(x, ...) rownames(x$projection),
levels = function(x) x$obsLevels,
sort = function(x) x[order(x[,1]),])
